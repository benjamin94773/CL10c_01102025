% !TeX program = pdflatex
\documentclass[11pt,a4paper]{article}

% Paquetes básicos
\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{amsmath, amssymb}
\usepackage{siunitx}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{caption}
\usepackage{booktabs}

\geometry{margin=2.5cm}
\hypersetup{colorlinks=true,linkcolor=blue,urlcolor=blue}

% Configuración de listings (bloques de comandos)
\lstdefinestyle{cmd}{
  basicstyle=\ttfamily\small,
  backgroundcolor=\color[HTML]{F7F7F7},
  frame=single,
  framerule=0.3pt,
  columns=fullflexible,
  breaklines=true,
  keepspaces=true
}

\newcommand{\code}[1]{\texttt{#1}}

\title{Programación Paralela con GNU Parallel: Informe de Resultados}
\author{Práctica: CSV y números aleatorios}
\date{\today}

\begin{document}
\maketitle

\section{Objetivo}
Comparar la ejecución en serie frente a la ejecución en paralelo (con GNU Parallel) en dos actividades:
\begin{itemize}
  \item Procesamiento de archivos CSV (cálculo de media y mediana por columna).
  \item Generación de archivos con números aleatorios y cómputo de suma por archivo.
\end{itemize}

\section{Entorno y reproducibilidad}
Se utilizó un contenedor Docker que extiende la imagen \code{alhumaidyaroob/gnu-parallel} para incluir Python~3.\footnote{\url{https://hub.docker.com/r/alhumaidyaroob/gnu-parallel}}

\subsection*{Construcción de la imagen}
\begin{lstlisting}[style=cmd]
docker build -t local/gnu-parallel-python:latest .
\end{lstlisting}

\subsection*{Ejecución dentro del contenedor}
Todos los comandos se ejecutaron montando el directorio de trabajo en \code{/work}:
\begin{lstlisting}[style=cmd]
docker run --rm -it -v ${PWD}:/work -w /work \
  local/gnu-parallel-python:latest bash -lc "<comandos>"
\end{lstlisting}

\section{Actividad 1: CSV en serie vs. paralelo}
\subsection{Generación de datos}
Se generaron tres archivos con \SI{200000}{} filas cada uno:
\begin{lstlisting}[style=cmd]
python .\data_gen.py --rows 200000
# output: data1.csv, data2.csv, data3.csv (columnas: value1,value2,value3)
\end{lstlisting}

\subsection{Script de procesamiento}
El script lee un CSV y entrega: archivo, columna, conteo, media, mediana y tiempo (s).
\begin{lstlisting}[style=cmd]
python .\script.py <archivo> --column value2
\end{lstlisting}

\subsection{Ejecución en serie}
Se ejecutó uno por vez dentro del contenedor:
\begin{lstlisting}[style=cmd]
python3 script.py data1.csv --column value2
python3 script.py data2.csv --column value2
python3 script.py data3.csv --column value2
\end{lstlisting}
Resultados (tiempo individual en segundos):
\begin{itemize}
  \item \code{data1.csv}: \SI{0.624}{} s
  \item \code{data2.csv}: \SI{0.623}{} s
  \item \code{data3.csv}: \SI{0.628}{} s
\end{itemize}
\textbf{Total en serie}: $0.624 + 0.623 + 0.628 \approx \SI{1.875}{}$ s.

\subsection{Ejecución en paralelo con GNU Parallel}
\begin{lstlisting}[style=cmd]
time parallel python3 script.py --column value2 ::: data1.csv data2.csv data3.csv
\end{lstlisting}
Tiempos por archivo reportados por el script: \SI{0.659}{} s, \SI{0.660}{} s, \SI{0.668}{} s.
\\\textbf{Tiempo total (\emph{real})}: \SI{1.021}{} s.

\subsection{Comparación y speed-up}
Se define la aceleración como:
\begin{equation}
  S = \frac{T_{\text{serie}}}{T_{\text{paralelo}}}
\end{equation}
Con $T_{\text{serie}} \approx \SI{1.875}{}$ s y $T_{\text{paralelo}} \approx \SI{1.021}{}$ s, se obtiene
\begin{equation}
  S \approx \frac{1.875}{1.021} \approx 1.84\times.
\end{equation}
\noindent
Observaciones: el tiempo total paralelo se acerca al de la tarea más lenta más el \emph{overhead}; al aumentar el trabajo (más filas), la ganancia suele mejorar.

\begin{table}[h]
  \centering
  \caption{Resumen de tiempos (Actividad CSV)}
  \begin{tabular}{@{}lll@{}}
    \toprule
    Modo & Métrica & Tiempo (s) \\
    \midrule
    Serie    & Suma de 3 tareas & 1.875 \\
    Paralelo & \emph{real} (wall clock) & 1.021 \\
    \bottomrule
  \end{tabular}
\end{table}

\section{Actividad 2: Archivos de números aleatorios}
\subsection{Caso A: 5 archivos, 100 números}
Generación y suma por archivo (paralelo):
\begin{lstlisting}[style=cmd]
seq 5 | parallel "shuf -i 1-1000 -n 100 > data{}.txt"
parallel "awk '{s+=\$1} END {print \"{}: \" s}' {}" ::: data*.txt | sort -V | tee sums.txt
\end{lstlisting}
Ejemplo de salida:
\begin{lstlisting}[style=cmd]
data1.txt: 51043
data2.txt: 47010
data3.txt: 50168
...
\end{lstlisting}

\subsection{Caso B: 20 archivos, 200 números}
Se automatizó en \code{numbers\_parallel\_20.sh}:
\begin{enumerate}
  \item Generar 20 archivos: \code{seq 20 | parallel "shuf -i 1-1000 -n 200 > data\{\}.txt"}
  \item Sumas en serie con \code{time} y en paralelo con \code{time parallel}.
\end{enumerate}
Tiempos registrados:
\begin{itemize}
  \item Serie (\emph{real}): \SI{0.081}{} s
  \item Paralelo (\emph{real}): \SI{0.253}{} s
\end{itemize}
Conclusión específica: con poco trabajo por archivo (200 números), el \textit{overhead} de lanzar tareas paralelas puede superar la ganancia, y la versión paralela resulta más lenta. Aumentar el tamaño (p.ej., \code{-n 10000}) suele revertir esto.

\section{Conclusiones}
\begin{itemize}
  \item El paralelismo reduce el tiempo de pared cuando cada tarea tiene suficiente cómputo y es independiente.
  \item El \emph{overhead} (procesos, orquestación, E/S, contenedores) puede anular la ventaja si la tarea es pequeña.
  \item En la actividad CSV, se obtuvo un speed-up aproximado de $\,\sim1.84\times$. Para cargas mayores (más filas), la aceleración debería aumentar.
  \item Ajustar \code{--jobs} en GNU Parallel al número de núcleos/recursos disponibles ayuda a aprovechar mejor el hardware.
  \item Scripts y contenedor reproducibles facilitan repetir y comparar los experimentos.
\end{itemize}

\section*{Anexos}
\subsection*{Silenciar aviso de citación de GNU Parallel}
\begin{lstlisting}[style=cmd]
docker run --rm -it local/gnu-parallel-python:latest bash -lc "parallel --citation"
\end{lstlisting}

\end{document}
